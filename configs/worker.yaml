# Worker 服务配置
worker:
  concurrency: 4
  queue_size: 1000
  retry_count: 3
  retry_delay: 1s
  timeout: 5m
  # Agent Job 拉取间隔（从事件存储 Claim）
  poll_interval: "2s"
  # Worker 能力列表；仅认领 Job.required_capabilities 被满足的 Job；空表示接受任意 Job（如 llm, tool, rag）
  # capabilities: ["llm", "tool"]
  
  # 队列公平性策略（2.0 starvation prevention）
  fairness_policy:
    realtime_weight: 70    # 实时队列权重 70%
    default_weight: 20     # 默认队列权重 20%
    background_weight: 8   # 后台队列权重 8%
    heavy_weight: 2        # 重任务队列权重 2%
    starvation_threshold: "5m"  # 低优先级任务等待超过 5 分钟，临时提升优先级

# 任务事件与元数据存储（与 API 共用 DSN 时，Worker Claim 执行 Job）
jobstore:
  type: "postgres"
  dsn: "postgres://aetheris:aetheris@localhost:5432/aetheris?sslmode=disable"
  lease_duration: "30s"

# 存储配置（当前元数据仅支持 memory；mysql 等需后续实现）
storage:
  metadata:
    type: "memory"
    dsn: ""
    pool_size: 0
  # 向量库：type=memory 为内存；collection 为默认索引/集合名（ingest 写入与 query 检索共用）
  # 其他 type（如 pgvector/milvus）需实现对应 Store 后在 store.go 中扩展
  vector:
    type: "memory"
    addr: ""
    db: ""
    collection: "default"
  object:
    type: "memory"
  cache:
    type: "memory"
  # 入库管线：batch_size（每批写入向量数）、concurrency（embedding/索引并发）
  ingest:
    batch_size: 100
    concurrency: 4

# 模型配置（LLM/Embedding/Vision）由 configs/model.yaml 合并提供，Worker 使用 LoadWorkerConfigWithModel 加载

# 切片配置
splitter:
  chunk_size: 1000
  chunk_overlap: 100
  max_chunks: 1000

# 日志配置
log:
  level: "info"
  format: "json"
  file: "worker.log"

# 监控配置（多 Worker 时可用环境变量 AETHERIS_WORKER_METRICS_PORT 指定不同端口，如 9094）
monitoring:
  prometheus:
    enable: true
    port: 9093